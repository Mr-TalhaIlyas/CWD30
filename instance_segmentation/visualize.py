#%%
import os
import sys
import random
import itertools
import colorsys

import numpy as np
from skimage.measure import find_contours
import matplotlib.pyplot as plt
from matplotlib import patches,  lines
from matplotlib.patches import Polygon
import IPython.display
import cv2
import matplotlib as mpl
mpl.rcParams['figure.dpi'] = 500
import pandas as pd
import matplotlib.pyplot as plt
# Root directory of the project
ROOT_DIR = os.path.abspath("../")

'''
Code adapted from: https://github.com/matterport/Mask_RCNN/blob/master/mrcnn/visualize.py
'''



############################################################
#  Visualization
############################################################

def display_images(images, titles=None, cols=4, cmap=None, norm=None,
                   interpolation=None):
    """Display the given set of images, optionally with titles.
    images: list or array of image tensors in HWC format.
    titles: optional. A list of titles to display with each image.
    cols: number of images per row
    cmap: Optional. Color map to use. For example, "Blues".
    norm: Optional. A Normalize instance to map values to colors.
    interpolation: Optional. Image interpolation to use for display.
    """
    titles = titles if titles is not None else [""] * len(images)
    rows = len(images) // cols + 1
    plt.figure(figsize=(14, 14 * rows // cols))
    i = 1
    for image, title in zip(images, titles):
        plt.subplot(rows, cols, i)
        plt.title(title, fontsize=9)
        plt.axis('off')
        plt.imshow(image.astype(np.uint8), cmap=cmap,
                   norm=norm, interpolation=interpolation)
        i += 1
    plt.show()


def random_colors(N, bright=True):
    """
    Generate random colors.
    To get visually distinct colors, generate them in HSV space then
    convert to RGB.
    """
    brightness = 1.0 if bright else 0.7
    hsv = [(i / N, 1, brightness) for i in range(N)]
    colors = list(map(lambda c: colorsys.hsv_to_rgb(*c), hsv))
    random.shuffle(colors)
    return colors


def apply_mask(image, mask, color, alpha=0.5):
    """Apply the given mask to the image.
    """
    for c in range(3):
        image[:, :, c] = np.where(mask == 1,
                                  image[:, :, c] *
                                  (1 - alpha) + alpha * color[c] * 255,
                                  image[:, :, c])
    return image


def display_instances(image, boxes, masks, class_ids, class_names,
                      scores=None, title="",
                      figsize=(16, 16), ax=None,
                      show_mask=True, show_bbox=True,
                      colors=None, captions=None):
    """
    boxes: [num_instance, (y1, x1, y2, x2, class_id)] in image coordinates.
    masks: [height, width, num_instances]
    class_ids: [num_instances]
    class_names: list of class names of the dataset
    scores: (optional) confidence scores for each box
    title: (optional) Figure title
    show_mask, show_bbox: To show masks and bounding boxes or not
    figsize: (optional) the size of the image
    colors: (optional) An array or colors to use with each object
    captions: (optional) A list of strings to use as captions for each object
    """
    # Number of instances
    N = boxes.shape[0]
    if not N:
        print("\n*** No instances to display *** \n")
    else:
        assert boxes.shape[0] == masks.shape[-1] == class_ids.shape[0]

    # If no axis is passed, create one and automatically call show()
    auto_show = False
    if not ax:
        _, ax = plt.subplots(1, figsize=figsize)
        auto_show = True

    # Generate random colors
    colors = colors or random_colors(N)

    # Show area outside image boundaries.
    height, width = image.shape[:2]
    ax.set_ylim(height + 10, -10)
    ax.set_xlim(-10, width + 10)
    ax.axis('off')
    ax.set_title(title)

    masked_image = image.astype(np.uint32).copy()
    for i in range(N):
        color = colors[i]

        # Bounding box
        if not np.any(boxes[i]):
            # Skip this instance. Has no bbox. Likely lost in image cropping.
            continue
        y1, x1, y2, x2 = boxes[i]
        if show_bbox:
            p = patches.Rectangle((x1, y1), x2 - x1, y2 - y1, linewidth=2,
                                alpha=0.7, linestyle="dashed",
                                edgecolor=color, facecolor='none')
            ax.add_patch(p)

        # Label
        if not captions:
            class_id = class_ids[i]
            score = scores[i] if scores is not None else None
            label = class_names[class_id]
            caption = "{} {:.3f}".format(label, score) if score else label
        else:
            caption = captions[i]
        ax.text(x1, y1 + 8, caption,
                color='w', size=11, backgroundcolor="none")

        # Mask
        mask = masks[:, :, i]
        if show_mask:
            masked_image = apply_mask(masked_image, mask, color)

         # Mask Polygon
        # Pad to ensure proper polygons for masks that touch image edges.
        padded_mask = np.zeros(
            (mask.shape[0] + 2, mask.shape[1] + 2), dtype=np.uint8)
        padded_mask[1:-1, 1:-1] = mask
        contours = find_contours(padded_mask, 0.5)
        for verts in contours:
            # Subtract the padding and flip (y, x) to (x, y)
            verts = np.fliplr(verts) - 1
            p = Polygon(verts, facecolor="none", edgecolor=color)
            ax.add_patch(p)
    ax.imshow(masked_image.astype(np.uint8))
    if auto_show:
        plt.show()
        
    ax.figure.canvas.draw()
    w, h = ax.figure.canvas.get_width_height()
    buf = np.frombuffer(ax.figure.canvas.tostring_rgb(), dtype=np.uint8)
    buf.shape = (h, w, 3)
    
    return buf#masked_image.astype(np.uint8)
def one_hot_encode_masks(mask):
    """Convert HxW mask to a one-hot encoded mask with dimensions HxWxK.
    
    Args:
    - mask (numpy.ndarray): An HxW array where each pixel's non-zero value indicates the instance it belongs to.

    Returns:
    - numpy.ndarray: A one-hot encoded mask with shape HxWxK, where K is the number of instances.
    """
    # Identify the unique instances while ignoring the background (assumed to be 0)
    instances = np.unique(mask)
    instances = instances[instances != 0]  # Remove background
    one_hot_masks = np.zeros((mask.shape[0], mask.shape[1], len(instances)), dtype=np.uint8)

    # Create a one-hot encoded mask for each instance
    for i, instance in enumerate(instances):
        one_hot_masks[:, :, i] = (mask == instance).astype(np.uint8)
    
    return one_hot_masks

def extract_bboxes(mask):
    boxes = np.zeros([mask.shape[-1], 4], dtype=np.int32)
    for i in range(mask.shape[-1]):
        m = mask[:, :, i]
        # Bounding box.
        horizontal_indicies = np.where(np.any(m, axis=0))[0]
        vertical_indicies = np.where(np.any(m, axis=1))[0]
        if horizontal_indicies.shape[0]:
            x1, x2 = horizontal_indicies[[0, -1]]
            y1, y2 = vertical_indicies[[0, -1]]
            # x2 and y2 should not be part of the box. Increment by 1.
            x2 += 1
            y2 += 1
        else:
            # No mask for this instance. Might happen due to
            # resizing or cropping. Set bbox to zeros
            x1, x2, y1, y2 = 0, 0, 0, 0
        boxes[i] = np.array([y1, x1, y2, x2])
    return boxes


#%%


image = cv2.imread('/home/user01/data/talha/phenobench/data/val/images/06-05_00160_P0038051.png') # Your loaded masks
image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
# masks = cv2.imread('/home/user01/data/talha/phenobench/data/val/leaf_instances/06-05_00160_P0038051.png',-1) # Your loaded RGB image
masks = cv2.imread('/home/user01/data/talha/phenobench/results/inat21/predictions/leaf_instances/06-05_00160_P0038051.png',-1) #
masks = one_hot_encode_masks(masks)

bbox = extract_bboxes(masks)

# Display the image with masks and bounding boxes
masked_image = display_instances(image, bbox, masks, class_ids=np.arange(masks.shape[-1]), 
                  class_names=['leaves']*len(bbox), scores=None)
# plt.imshow(masked_image)
# %%
/home/user01/data/talha/phenobench/data/val/images/06-05_00160_P0038051.png
/home/user01/data/talha/phenobench/results/inat21/predictions/leaf_instances
